{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qdYdZgdLR1_s"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, time, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import xarray as xr\n",
    "from ocf_blosc2 import Blosc2\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torchinfo import summary\n",
    "import json\n",
    "import glob\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wf080q8HR1_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gr5D2pdnR1_x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file /data/processed_data/processed_train_dev.hdf5.\n",
      "Warming up the dataloader!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 19949.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset len: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import HDF5Dataset\n",
    "dataset = HDF5Dataset(['/data/processed_data/processed_train_dev.hdf5'], \"/data/sat_np/\", \"/data/weather_np/\", True, True, True, True)\n",
    "data_loader = DataLoader(dataset, batch_size=16, pin_memory=True, num_workers=8, shuffle=False)\n",
    "print(f\"train dataset len: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CIPuwDufR1_y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "OurResnet2                                         [1, 48]                   --\n",
       "├─VideoResNet: 1-1                                 [1, 256]                  --\n",
       "│    └─R2Plus1dStem: 2-1                           [1, 64, 12, 64, 64]       --\n",
       "│    │    └─Conv3d: 3-1                            [1, 45, 12, 64, 64]       24,255\n",
       "│    │    └─BatchNorm3d: 3-2                       [1, 45, 12, 64, 64]       90\n",
       "│    │    └─ReLU: 3-3                              [1, 45, 12, 64, 64]       --\n",
       "│    │    └─Conv3d: 3-4                            [1, 64, 12, 64, 64]       8,640\n",
       "│    │    └─BatchNorm3d: 3-5                       [1, 64, 12, 64, 64]       128\n",
       "│    │    └─ReLU: 3-6                              [1, 64, 12, 64, 64]       --\n",
       "│    └─Sequential: 2-2                             [1, 64, 12, 64, 64]       --\n",
       "│    │    └─BasicBlock: 3-7                        [1, 64, 12, 64, 64]       222,016\n",
       "│    │    └─BasicBlock: 3-8                        [1, 64, 12, 64, 64]       222,016\n",
       "│    └─Sequential: 2-3                             [1, 128, 6, 32, 32]       --\n",
       "│    │    └─BasicBlock: 3-9                        [1, 128, 6, 32, 32]       583,960\n",
       "│    │    └─BasicBlock: 3-10                       [1, 128, 6, 32, 32]       886,400\n",
       "│    └─Sequential: 2-4                             [1, 256, 3, 16, 16]       --\n",
       "│    │    └─BasicBlock: 3-11                       [1, 256, 3, 16, 16]       2,332,464\n",
       "│    │    └─BasicBlock: 3-12                       [1, 256, 3, 16, 16]       3,542,272\n",
       "│    └─Sequential: 2-5                             [1, 512, 2, 8, 8]         --\n",
       "│    │    └─BasicBlock: 3-13                       [1, 512, 2, 8, 8]         9,333,092\n",
       "│    │    └─BasicBlock: 3-14                       [1, 512, 2, 8, 8]         14,162,432\n",
       "│    └─AdaptiveAvgPool3d: 2-6                      [1, 512, 1, 1, 1]         --\n",
       "│    └─Sequential: 2-7                             [1, 256]                  --\n",
       "│    │    └─Linear: 3-15                           [1, 384]                  196,992\n",
       "│    │    └─Mish: 3-16                             [1, 384]                  --\n",
       "│    │    └─Linear: 3-17                           [1, 256]                  98,560\n",
       "│    │    └─Mish: 3-18                             [1, 256]                  --\n",
       "├─VideoResNet: 1-2                                 [1, 256]                  --\n",
       "│    └─R2Plus1dStem: 2-8                           [1, 64, 6, 64, 64]        --\n",
       "│    │    └─Conv3d: 3-19                           [1, 45, 6, 64, 64]        22,050\n",
       "│    │    └─BatchNorm3d: 3-20                      [1, 45, 6, 64, 64]        90\n",
       "│    │    └─ReLU: 3-21                             [1, 45, 6, 64, 64]        --\n",
       "│    │    └─Conv3d: 3-22                           [1, 64, 6, 64, 64]        8,640\n",
       "│    │    └─BatchNorm3d: 3-23                      [1, 64, 6, 64, 64]        128\n",
       "│    │    └─ReLU: 3-24                             [1, 64, 6, 64, 64]        --\n",
       "│    └─Sequential: 2-9                             [1, 64, 6, 64, 64]        --\n",
       "│    │    └─BasicBlock: 3-25                       [1, 64, 6, 64, 64]        222,016\n",
       "│    │    └─BasicBlock: 3-26                       [1, 64, 6, 64, 64]        222,016\n",
       "│    └─Sequential: 2-10                            [1, 128, 3, 32, 32]       --\n",
       "│    │    └─BasicBlock: 3-27                       [1, 128, 3, 32, 32]       583,960\n",
       "│    │    └─BasicBlock: 3-28                       [1, 128, 3, 32, 32]       886,400\n",
       "│    └─Sequential: 2-11                            [1, 256, 2, 16, 16]       --\n",
       "│    │    └─BasicBlock: 3-29                       [1, 256, 2, 16, 16]       2,332,464\n",
       "│    │    └─BasicBlock: 3-30                       [1, 256, 2, 16, 16]       3,542,272\n",
       "│    └─Sequential: 2-12                            [1, 512, 1, 8, 8]         --\n",
       "│    │    └─BasicBlock: 3-31                       [1, 512, 1, 8, 8]         9,333,092\n",
       "│    │    └─BasicBlock: 3-32                       [1, 512, 1, 8, 8]         14,162,432\n",
       "│    └─AdaptiveAvgPool3d: 2-13                     [1, 512, 1, 1, 1]         --\n",
       "│    └─Sequential: 2-14                            [1, 256]                  --\n",
       "│    │    └─Linear: 3-33                           [1, 384]                  196,992\n",
       "│    │    └─Mish: 3-34                             [1, 384]                  --\n",
       "│    │    └─Linear: 3-35                           [1, 256]                  98,560\n",
       "│    │    └─Mish: 3-36                             [1, 256]                  --\n",
       "├─Sequential: 1-3                                  [1, 128]                  --\n",
       "│    └─Dropout: 2-15                               [1, 512]                  --\n",
       "│    └─Linear: 2-16                                [1, 256]                  131,328\n",
       "│    └─Mish: 2-17                                  [1, 256]                  --\n",
       "│    └─Linear: 2-18                                [1, 128]                  32,896\n",
       "│    └─Mish: 2-19                                  [1, 128]                  --\n",
       "├─Embedding: 1-4                                   [1, 12]                   4,320\n",
       "├─Embedding: 1-5                                   [1, 12]                   4,320\n",
       "├─ResFCNet2: 1-6                                   [1, 48]                   --\n",
       "│    └─Sequential: 2-20                            [1, 48]                   --\n",
       "│    │    └─Linear: 3-37                           [1, 128]                  21,120\n",
       "│    │    └─ResidualLinearBlock2: 3-38             [1, 128]                  33,536\n",
       "│    │    └─ResidualLinearBlock2: 3-39             [1, 128]                  33,536\n",
       "│    │    └─ResidualLinearBlock2: 3-40             [1, 128]                  33,536\n",
       "│    │    └─ResidualLinearBlock2: 3-41             [1, 128]                  33,536\n",
       "│    │    └─Mish: 3-42                             [1, 128]                  --\n",
       "│    │    └─Linear: 3-43                           [1, 48]                   6,192\n",
       "│    │    └─Mish: 3-44                             [1, 48]                   --\n",
       "====================================================================================================\n",
       "Total params: 63,558,749\n",
       "Trainable params: 63,558,749\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 62.56\n",
       "====================================================================================================\n",
       "Input size (MB): 12.58\n",
       "Forward/backward pass size (MB): 1489.80\n",
       "Params size (MB): 254.23\n",
       "Estimated Total Size (MB): 1756.62\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "START_EPOCH = 0\n",
    "LR = 1e-3\n",
    "from submission.model import OurResnet2\n",
    "model = OurResnet2(image_size=128, device=device).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimiser = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.02)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimiser, T_max=10, eta_min=7e-5)\n",
    "summary(model, input_size=[(1, 12), (1, 11, 12, 128, 128), (1, 10, 6, 128, 128), (1, 3)])\n",
    "# x = torch.randn((1, 12)).to(device)\n",
    "# y = torch.randn((1, 1, 12, 128, 128)).to(device)\n",
    "# z = torch.randn((1, 10, 6, 128, 128)).to(device)\n",
    "# a = torch.randn((1, 3)).to(device)\n",
    "# model(x, y, z, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "def hasNan(tensor):\n",
    "    return torch.isnan(tensor).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4tuuVQz0R1_y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model key ExtraEmbedding_TemporalResnet2+1Combo-PVResFCNet2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/7 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/dsingh/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/dsingh/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/dsingh/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/dsingh/source/devksingh4/climatehack-2023/vit/dataset.py\", line 128, in __getitem__\n    data.append(torch.from_numpy(crop).permute(2, 1, 3, 4))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIndexError: Dimension out of range (expected to be in range of [-4, 3], but got 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpv_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhrv_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnwp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpv_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/dsingh/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/dsingh/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/dsingh/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/dsingh/source/devksingh4/climatehack-2023/vit/dataset.py\", line 128, in __getitem__\n    data.append(torch.from_numpy(crop).permute(2, 1, 3, 4))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIndexError: Dimension out of range (expected to be in range of [-4, 3], but got 4)\n"
     ]
    }
   ],
   "source": [
    "MODEL_KEY=\"ExtraEmbedding_TemporalResnet2+1Combo-PVResFCNet2\"\n",
    "print(f\"Training model key {MODEL_KEY}\")\n",
    "from tqdm import tqdm\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    count = 0\n",
    "    for (pv_features, hrv_features, nwp, extra, pv_targets) in (pbar := tqdm(data_loader, total=len(data_loader), ascii=True)):\n",
    "        optimiser.zero_grad()\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            real_extra = extra[:, 2:]\n",
    "            if hasNan(pv_features) or hasNan(hrv_features) or hasNan(nwp) or hasNan(extra) or hasNan(pv_targets):\n",
    "                print(f\"Found nan {i}\")\n",
    "                continue\n",
    "            predictions = model(\n",
    "                pv_features.to(device,dtype=torch.float),\n",
    "                hrv_features.to(device,dtype=torch.float),\n",
    "                nwp.to(device,dtype=torch.float),\n",
    "                real_extra.to(device,dtype=torch.float),\n",
    "            )\n",
    "            # print(pv_features.shape, hrv_features.shape, nwp.shape, real_extra.shape)\n",
    "            loss = criterion(predictions, pv_targets.to(device, dtype=torch.float))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimiser.step()\n",
    "\n",
    "        size = int(pv_targets.size(0))\n",
    "        running_loss += float(loss) * size\n",
    "        count += size\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            writer.add_scalar(f\"Loss/train_batch_level\", (running_loss / count), epoch * len(data_loader) + i)\n",
    "            pbar.set_description(f\"Epoch {START_EPOCH + epoch + 1}, {i + 1}: {running_loss / count}\")\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch {START_EPOCH + epoch + 1}, {i + 1}: {running_loss / count}\")\n",
    "            writer.add_scalar(f\"Loss/train_ep_level\", (running_loss / count), START_EPOCH + epoch + 1)\n",
    "        if i % 3000 == 2999:\n",
    "            torch.save(model.state_dict(), f\"./cpts/{MODEL_KEY}-ep{START_EPOCH + epoch + 1}.pt\")\n",
    "        i += 1\n",
    "    lr_scheduler.step() \n",
    "    current_lr = lr_scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {START_EPOCH + epoch + 1}: {running_loss / count} (LR: {current_lr})\")\n",
    "    writer.add_scalar(f\"LR\", current_lr, START_EPOCH + epoch + 1)\n",
    "    torch.save(model.state_dict(), f\"./cpts/{MODEL_KEY}-ep{START_EPOCH + epoch + 1}.pt\")\n",
    "    print(\"Saved model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pv_features, hrv_features, weather_features, extra, pv_targets = dataset[i]\n",
    "    print(hrv_features.shape, weather_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
