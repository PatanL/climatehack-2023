{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdYdZgdLR1_s"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, time, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import xarray as xr\n",
    "from ocf_blosc2 import Blosc2\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torchinfo import summary\n",
    "import json\n",
    "import glob\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wf080q8HR1_s"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gr5D2pdnR1_x"
   },
   "outputs": [],
   "source": [
    "from dataset import HDF5Dataset\n",
    "dataset = HDF5Dataset(['/data/processed_data/processed_train_1.hdf5'], \"/data/satellite-nonhrv_concat/2021.zarr\", \"/data/weather_concat/2021.zarr\", True, True, True, True)\n",
    "data_loader = DataLoader(dataset, batch_size=16, pin_memory=True, num_workers=8, shuffle=False)\n",
    "print(f\"train dataset len: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIPuwDufR1_y"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "START_EPOCH = 0\n",
    "LR = 1e-3\n",
    "from submission.model import OurResnet2\n",
    "model = OurResnet2(image_size=128, device=device).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimiser = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.02)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimiser, T_max=10, eta_min=7e-5)\n",
    "summary(model, input_size=[(1, 12), (1, 11, 12, 128, 128), (1, 10, 6, 128, 128), (1, 3)])\n",
    "# x = torch.randn((1, 12)).to(device)\n",
    "# y = torch.randn((1, 1, 12, 128, 128)).to(device)\n",
    "# z = torch.randn((1, 10, 6, 128, 128)).to(device)\n",
    "# a = torch.randn((1, 3)).to(device)\n",
    "# model(x, y, z, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "def hasNan(tensor):\n",
    "    return torch.isnan(tensor).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tuuVQz0R1_y"
   },
   "outputs": [],
   "source": [
    "MODEL_KEY=\"ExtraEmbedding_TemporalResnet2+1Combo-PVResFCNet2\"\n",
    "print(f\"Training model key {MODEL_KEY}\")\n",
    "from tqdm import tqdm\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    count = 0\n",
    "    for (pv_features, hrv_features, nwp, extra, pv_targets) in (pbar := tqdm(data_loader, total=len(data_loader), ascii=True)):\n",
    "        optimiser.zero_grad()\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            real_extra = extra[:, 2:]\n",
    "            if hasNan(pv_features) or hasNan(hrv_features) or hasNan(nwp) or hasNan(extra) or hasNan(pv_targets):\n",
    "                print(f\"Found nan {i}\")\n",
    "                continue\n",
    "            predictions = model(\n",
    "                pv_features.to(device,dtype=torch.float),\n",
    "                hrv_features.to(device,dtype=torch.float),\n",
    "                nwp.to(device,dtype=torch.float),\n",
    "                real_extra.to(device,dtype=torch.float),\n",
    "            )\n",
    "            # print(pv_features.shape, hrv_features.shape, nwp.shape, real_extra.shape)\n",
    "            loss = criterion(predictions, pv_targets.to(device, dtype=torch.float))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimiser.step()\n",
    "\n",
    "        size = int(pv_targets.size(0))\n",
    "        running_loss += float(loss) * size\n",
    "        count += size\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            writer.add_scalar(f\"Loss/train_batch_level\", (running_loss / count), epoch * len(data_loader) + i)\n",
    "            pbar.set_description(f\"Epoch {START_EPOCH + epoch + 1}, {i + 1}: {running_loss / count}\")\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch {START_EPOCH + epoch + 1}, {i + 1}: {running_loss / count}\")\n",
    "            writer.add_scalar(f\"Loss/train_ep_level\", (running_loss / count), START_EPOCH + epoch + 1)\n",
    "        if i % 3000 == 2999:\n",
    "            torch.save(model.state_dict(), f\"./cpts/{MODEL_KEY}-ep{START_EPOCH + epoch + 1}.pt\")\n",
    "        i += 1\n",
    "    lr_scheduler.step() \n",
    "    current_lr = lr_scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {START_EPOCH + epoch + 1}: {running_loss / count} (LR: {current_lr})\")\n",
    "    writer.add_scalar(f\"LR\", current_lr, START_EPOCH + epoch + 1)\n",
    "    torch.save(model.state_dict(), f\"./cpts/{MODEL_KEY}-ep{START_EPOCH + epoch + 1}.pt\")\n",
    "    print(\"Saved model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pv_features, hrv_features, weather_features, extra, pv_targets = dataset[i]\n",
    "    print(hrv_features.shape, weather_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
